{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python: Basics of Double Machine Learning\n",
    "\n",
    "**Remark**: This notebook has a long computation time due to the large number of simulations.\n",
    "\n",
    "This notebooks contains the detailed simulations according to the introduction to double machine learning in the [User Guide](https://docs.doubleml.org/stable/guide/basics.html) of the DoubleML package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "\n",
    "from doubleml import DoubleMLData\n",
    "from doubleml import DoubleMLPLR\n",
    "from doubleml.datasets import make_plr_CCDDHNR2018\n",
    "\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process (DGP)\n",
    "\n",
    "We consider the following partially linear model:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_i &= \\theta_0 d_i + g_0(x_i) + \\zeta_i, & \\zeta_i \\sim \\mathcal{N}(0,1), \\\\\n",
    "d_i &= m_0(x_i) + v_i, & v_i \\sim \\mathcal{N}(0,1),\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "with covariates $x_i \\sim \\mathcal{N}(0, \\Sigma)$, where $\\Sigma$ is a matrix with entries $\\Sigma_{kj} = 0.7^{|j-k|}$. We are interested in performing valid inference on the causal parameter $\\theta_0$. The true parameter $\\theta_0$ is set to $0.5$ in our simulation experiment.\n",
    "\n",
    "The nuisance functions are given by:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "m_0(x_i) &= x_{i,1} + \\frac{1}{4}  \\frac{\\exp(x_{i,3})}{1+\\exp(x_{i,3})}, \\\\\n",
    "g_0(x_i) &= \\frac{\\exp(x_{i,1})}{1+\\exp(x_{i,1})} + \\frac{1}{4} x_{i,3}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate ``n_rep`` replications of the data generating process with sample size ``n_obs`` and compare the performance of different estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "n_rep = 1000\n",
    "n_obs = 500\n",
    "n_vars = 5\n",
    "alpha = 0.5\n",
    "\n",
    "data = list()\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    (x, y, d) = make_plr_CCDDHNR2018(alpha=alpha, n_obs=n_obs, dim_x=n_vars, return_type='array')\n",
    "    data.append((x, y, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization Bias in Simple ML-Approaches\n",
    "\n",
    "Naive inference that is based on a direct application of machine learning methods to estimate the causal parameter, $\\theta_0$, is generally invalid. The use of machine learning methods introduces a bias that arises due to regularization. A simple ML approach is given by randomly splitting the sample into two parts. On the auxiliary sample indexed by $i \\in I^C$ the nuisance function $g_0(X)$ is estimated with an ML method, for example a random forest learner. Given the estimate $\\hat{g}_0(X)$, the final estimate of $\\theta_0$ is obtained as ($n=N/2$) using the other half of observations indexed with $i \\in I$\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_0 = \\left(\\frac{1}{n} \\sum_{i\\in I} D_i^2\\right)^{-1} \\frac{1}{n} \\sum_{i\\in I} D_i (Y_i - \\hat{g}_0(X_i)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this corresponds to a \"non-orthogonal\" score, which is not implemented in the DoubleML package, we need to define a custom callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.75217411, -0.04289889, -0.98896007, -2.27055944, -0.13779274],\n",
       "        [-1.21899093, -0.50512348, -0.58591202,  0.50060461, -0.72953668],\n",
       "        [ 0.74898989, -0.17721147,  0.04325984,  1.52661352, -0.28910716],\n",
       "        ...,\n",
       "        [ 0.82968202, -0.40698762, -0.31533197, -1.03924854, -0.03358848],\n",
       "        [ 0.38271595,  2.21050245,  1.32501648,  1.06500662,  1.11033521],\n",
       "        [-2.19460042, -1.75362396, -1.30346081, -0.78699269, -0.77108774]]),\n",
       " array([-8.49563690e-01,  4.34901934e-01,  3.30938301e-01,  2.70365147e+00,\n",
       "         1.14204522e+00,  1.83031842e+00,  2.05815065e+00,  1.17616641e+00,\n",
       "         1.24255021e+00,  1.14492912e+00,  1.63238862e-01,  9.32057818e-01,\n",
       "         4.56654577e-01,  5.31398787e-01,  2.67567278e-01,  2.89390856e+00,\n",
       "         2.97427505e+00,  1.29680867e+00, -8.01752240e-02,  2.29521635e+00,\n",
       "         9.43235890e-01,  8.92908710e-01, -2.39512923e+00,  1.87264161e+00,\n",
       "         3.57172454e+00, -7.74167321e-01,  7.47924880e-01, -2.47117877e-02,\n",
       "         1.21516991e+00,  3.76505583e-01, -1.91644476e+00, -6.35973702e-01,\n",
       "         2.62093586e+00, -6.87681442e-01,  7.00820855e-01,  1.71912876e+00,\n",
       "        -1.15282003e+00,  3.01168040e+00,  6.02114813e-01, -1.95500244e-01,\n",
       "         1.01363489e+00,  2.05005719e+00,  4.38276525e-01, -1.43343319e-01,\n",
       "         7.86255137e-01,  1.56976634e+00,  2.11290639e+00, -1.58914219e+00,\n",
       "         5.60403194e-01, -1.30489596e+00, -1.32673531e+00,  8.27979784e-01,\n",
       "         1.35012685e+00,  8.50662860e-01, -2.46113261e+00,  1.96867707e+00,\n",
       "         1.51964331e+00,  8.68749776e-01, -1.00471216e+00,  2.10972555e+00,\n",
       "         2.61676665e+00,  1.54370414e+00,  1.63449365e+00,  6.33297664e-01,\n",
       "         2.29169376e+00,  2.48437425e+00,  1.94570652e-01, -7.69237268e-01,\n",
       "         6.49725073e-01,  1.40337370e+00,  5.18036970e-01,  6.70778132e-01,\n",
       "        -4.68653389e-02,  8.14261208e-01, -2.62737501e-01,  1.56587581e+00,\n",
       "         2.41107284e-01,  2.09980100e+00, -8.32638092e-01, -1.05485802e+00,\n",
       "        -1.40182060e-01, -1.96823174e+00,  1.93192582e+00, -1.34588040e-01,\n",
       "         1.32852949e+00,  8.39645431e-01, -3.08916219e+00, -2.05208945e-01,\n",
       "         1.04485607e+00,  2.23337310e-01, -1.32042401e+00,  1.94902587e+00,\n",
       "         4.98726378e-01,  1.37001143e-01, -9.53818037e-01,  2.16163756e-01,\n",
       "         8.05658048e-01, -3.43612779e-01,  5.62823785e+00,  4.07537233e-01,\n",
       "         1.42064155e+00,  2.43212778e+00,  1.38780070e+00,  1.56650537e+00,\n",
       "         3.11200146e-01, -1.79321640e+00,  1.67248154e+00,  2.18273879e-01,\n",
       "         1.55945526e+00,  1.58073412e-01,  1.20612984e+00,  1.22477350e+00,\n",
       "        -7.05399560e-01,  5.04921735e-01,  1.52588179e+00,  2.79481863e+00,\n",
       "        -2.55680370e-02,  8.58837096e-01,  1.03211984e+00,  3.61755202e+00,\n",
       "        -1.00510469e+00, -1.39322663e-01,  1.67086621e+00,  1.56986972e+00,\n",
       "         1.02295597e+00, -3.23282989e-01,  4.78480234e-01,  5.38168472e-01,\n",
       "         9.82522146e-01, -2.15793832e-01, -6.30695899e-01,  6.76210538e-01,\n",
       "         2.29502424e+00,  1.28165977e+00,  2.43776330e+00, -1.36929123e+00,\n",
       "         1.78462039e+00,  5.49067802e-01, -6.11589321e-01,  9.72336663e-01,\n",
       "         1.29495537e+00,  2.15685835e+00,  2.21794322e+00, -3.62519358e-01,\n",
       "         2.10222459e+00, -1.51743391e+00, -8.64623035e-01,  1.24801682e+00,\n",
       "        -7.30895197e-02,  1.59149493e+00,  1.19088486e+00,  4.84182151e-01,\n",
       "        -4.78561966e-01, -2.08789847e+00,  8.42072160e-01, -9.97236337e-01,\n",
       "         2.06579204e+00,  8.39852026e-01, -8.10969360e-01,  1.48346328e+00,\n",
       "         4.24582099e-01,  5.96152025e-01,  9.51792955e-01, -1.29411316e-01,\n",
       "         1.47442326e+00, -1.18920969e+00, -8.52136807e-01, -1.16415964e+00,\n",
       "        -8.27547405e-01, -4.05526339e-01,  1.94099291e+00, -6.17750498e-01,\n",
       "         7.22827883e-01, -2.39942017e+00,  3.45970946e-01, -6.35252416e-01,\n",
       "         9.16134059e-02,  3.92342987e-01,  1.08445453e+00,  1.36664565e+00,\n",
       "         9.54104230e-01,  6.95990306e-01,  2.27740119e+00,  1.79595179e+00,\n",
       "         2.32991791e+00,  3.62454238e-01,  2.26459811e+00,  1.57056863e+00,\n",
       "         8.00737533e-02,  3.01127011e+00,  1.37364793e+00,  1.41810890e+00,\n",
       "         2.85318012e+00, -6.87496658e-01,  1.52093698e+00,  2.25496188e+00,\n",
       "         3.38259291e+00, -5.24968810e-01, -1.82476182e+00,  1.15653207e-01,\n",
       "        -8.25989223e-01,  1.87292297e+00,  2.52080689e+00,  1.43670418e+00,\n",
       "        -1.72286966e-01,  1.64502839e+00,  2.61687127e+00, -9.70470214e-01,\n",
       "        -6.07413683e-02, -1.22362251e+00, -6.26175554e-01,  1.85119594e+00,\n",
       "         4.24799812e-01,  2.49857962e+00, -2.96486544e-01,  1.32241773e+00,\n",
       "         1.36037093e-01, -2.68974550e+00,  1.59698376e+00, -4.99848806e-01,\n",
       "        -1.20297778e+00,  1.57817917e+00,  1.50090336e+00,  1.33489844e+00,\n",
       "         4.50636177e-01, -2.21659762e+00, -2.50264407e-02,  1.60164718e+00,\n",
       "         3.37976529e+00,  2.64911513e+00,  9.71331259e-01,  8.65186303e-02,\n",
       "        -2.18202979e-01, -5.39202365e-01, -4.69984354e-03, -1.15438321e+00,\n",
       "         3.95177456e+00,  2.50104810e+00,  1.36398274e+00,  3.37931300e+00,\n",
       "         1.24087975e+00,  1.61992718e+00,  3.57204794e-01,  3.31873601e+00,\n",
       "         6.10438439e-01,  9.85019678e-01,  1.75585389e+00,  3.06125558e+00,\n",
       "         4.48124035e-01, -6.05419990e-01,  5.81001589e-01,  1.71733625e+00,\n",
       "         4.56360349e-01,  2.25154688e+00, -1.81839029e+00,  1.51136824e-01,\n",
       "        -1.27256009e+00,  1.79874739e+00, -8.98419759e-01, -1.15762356e+00,\n",
       "         1.19345155e+00,  2.94243779e-01, -6.34644883e-01,  9.27142478e-01,\n",
       "        -2.66789107e+00, -1.92769962e+00, -4.71531015e-01,  1.05275344e+00,\n",
       "        -4.62849513e-01, -5.73067332e-02,  6.68308540e-01, -2.36396492e-01,\n",
       "        -2.96272932e-01,  7.24023528e-01,  1.43868815e+00, -1.08878588e-01,\n",
       "        -2.09366032e+00,  2.81097920e+00,  3.38199106e+00,  1.77839497e+00,\n",
       "         6.89484811e-01,  1.67475537e+00, -1.13436749e+00,  7.42357968e-02,\n",
       "         1.00465480e+00,  2.28836790e+00, -6.82538829e-01, -1.02084301e+00,\n",
       "         2.76332204e+00,  3.40245681e+00,  1.10585404e+00, -1.56681164e+00,\n",
       "        -2.48349172e+00,  1.88091095e+00,  1.30026700e+00,  3.15072940e-01,\n",
       "         3.78799435e+00, -1.02826782e+00, -1.42338755e-01, -3.96990731e-01,\n",
       "         4.77179175e-01,  1.64082065e+00,  2.38263931e+00, -7.24501871e-01,\n",
       "         2.31537802e+00,  2.03862950e+00,  8.95995278e-01, -1.51523252e+00,\n",
       "         2.70733739e+00,  1.81195000e+00,  2.30651122e-01,  1.52219776e+00,\n",
       "        -8.51815330e-01, -1.88062474e+00,  2.71585738e-01,  2.49162509e+00,\n",
       "         1.65589055e+00, -1.62912896e+00,  1.35551652e+00, -1.33169743e-01,\n",
       "        -2.20470794e+00, -1.41659543e+00,  4.93586084e-02,  3.46248666e+00,\n",
       "         1.66406678e+00, -1.36766740e-01,  2.25627046e+00, -1.42334750e+00,\n",
       "         2.25615349e+00, -1.41719998e+00, -7.31906287e-01,  1.55884199e+00,\n",
       "        -8.53431095e-02,  1.73591007e+00, -7.29937866e-01,  5.95535454e-01,\n",
       "        -1.21822955e+00, -5.96891856e-01,  4.73127543e-01, -1.84282653e+00,\n",
       "         2.35957018e-01,  8.30258163e-01, -1.04508193e-01,  2.42081658e+00,\n",
       "        -3.41409684e-01, -4.12127730e-01, -5.97117209e-01,  1.46334422e+00,\n",
       "         1.25438913e+00, -2.37179151e-01,  7.04417834e-01,  7.85985399e-01,\n",
       "         1.09060604e-02, -3.79241246e-02, -1.63715823e+00,  3.48382634e+00,\n",
       "        -2.13636274e-01, -2.39475158e+00, -1.15536727e+00, -7.76052123e-01,\n",
       "        -1.57890456e+00,  4.65131089e+00, -1.67528765e-01,  1.50638231e+00,\n",
       "         8.98411948e-01, -3.11678514e-01, -1.36859415e+00,  4.28141726e-01,\n",
       "         2.44378292e-01,  2.64612327e+00,  3.04016811e+00,  9.78419383e-01,\n",
       "        -6.13433049e-01,  1.02540187e+00,  1.63323889e+00,  2.70049742e+00,\n",
       "         4.83293690e-01,  1.28705455e+00, -9.29009609e-01,  1.22411699e+00,\n",
       "         1.36793399e+00,  1.90845294e+00,  2.18195047e+00,  2.05905017e+00,\n",
       "         7.58506012e-01, -1.86675969e+00,  2.00709618e+00,  3.49854450e+00,\n",
       "         1.82934928e+00,  1.52139331e-01, -2.48078322e+00,  1.29348161e+00,\n",
       "         1.72533145e+00, -7.43287225e-01, -4.64737838e-01, -1.02710841e+00,\n",
       "         3.15700945e-01,  2.31391260e+00,  2.42028475e-01, -1.74844282e-01,\n",
       "         2.87043849e+00,  3.16520210e+00, -3.33449241e-01, -2.64447752e-01,\n",
       "         2.36361702e+00,  1.69712332e-01,  1.01111859e-01,  1.50630960e-01,\n",
       "        -3.50488834e-01,  4.70000478e-01,  8.80241388e-01,  4.47364414e-01,\n",
       "         1.74276139e+00,  5.42501303e-01,  4.17803518e-01, -3.62754521e-01,\n",
       "        -9.83927968e-01,  7.59710171e-01, -7.01252642e-01,  1.76606491e+00,\n",
       "         9.62256144e-01,  1.39284210e+00,  1.43145207e+00,  1.10901449e+00,\n",
       "        -1.31437244e+00,  6.44477750e-02, -2.32106661e-01,  9.31287181e-01,\n",
       "         2.25168048e+00,  1.81006292e+00,  1.02907249e+00,  1.51632712e+00,\n",
       "        -2.07629246e-02, -3.11400350e+00,  3.61858874e-01,  6.73978429e-01,\n",
       "         1.55430524e+00, -5.20274791e-01,  1.72259347e+00,  1.76055120e+00,\n",
       "         2.10621138e+00,  2.06929261e+00,  7.06601269e-01,  2.38222538e+00,\n",
       "         2.93266826e+00,  1.04811966e+00, -1.54138232e+00, -2.14629566e+00,\n",
       "         5.63645609e-01, -5.02551862e-01,  3.30779274e-01,  3.01137828e+00,\n",
       "        -2.96928794e+00,  3.80278481e-01,  2.66774919e+00,  1.18187490e+00,\n",
       "         4.75567451e-01,  1.46611563e+00, -1.76031257e+00, -1.80384574e-01,\n",
       "         1.81783045e+00,  1.19109271e-01,  2.70722125e+00,  1.32389919e+00,\n",
       "        -2.44604000e+00,  2.63706151e+00, -2.30039010e-02,  4.66551389e-01,\n",
       "         1.79663955e+00,  1.78375285e+00,  3.21093526e+00,  3.54549426e+00,\n",
       "         9.92713214e-01, -2.00692728e-01,  2.23205942e+00,  4.22297139e+00,\n",
       "         1.08175820e-01, -4.94707769e-01,  5.72265929e-01,  6.37334648e-01,\n",
       "         7.89918018e-01, -7.47922236e-01, -5.34154685e-01,  3.45438531e-01,\n",
       "         5.89637334e-01,  1.42862725e+00,  3.40957575e+00,  1.02840839e+00,\n",
       "         3.22266732e-01,  1.84499670e+00, -9.10078735e-01, -1.07691268e+00,\n",
       "        -7.99722755e-01, -1.75127454e+00, -8.19540836e-01, -2.09009995e+00,\n",
       "         8.48935978e-01,  9.36714683e-01,  1.41664117e+00, -2.26344078e+00]),\n",
       " array([-2.04884948e+00, -5.94445715e-01, -1.51570448e-01,  3.34141059e-02,\n",
       "        -1.59324742e+00,  7.94506998e-01,  1.25458419e+00,  1.73563794e+00,\n",
       "         1.60096621e+00,  4.67573659e-01,  9.29726178e-01,  1.05960502e+00,\n",
       "         3.73762107e-03,  2.78494226e-01, -2.24304138e-04,  5.40542301e-02,\n",
       "         2.15604429e+00, -1.03856109e+00,  3.42958374e-01,  2.25406433e+00,\n",
       "         1.57121429e+00,  1.16462230e+00, -2.12021555e+00,  1.28845182e+00,\n",
       "         7.07588845e-01, -1.68746565e+00,  1.41215136e+00,  4.19445468e-01,\n",
       "        -4.67948935e-01, -6.24875312e-01, -4.77013370e-01, -2.80681665e+00,\n",
       "         1.34566979e+00, -1.97356095e+00,  5.63144346e-01,  1.06666005e+00,\n",
       "        -2.31266728e+00,  1.25301998e+00, -3.62077240e-01, -7.69010276e-01,\n",
       "         5.26785460e-01,  8.00108084e-01,  1.82250330e+00, -6.40431604e-02,\n",
       "         2.84186138e-01,  5.68145523e-01,  7.11853748e-01, -6.87994301e-01,\n",
       "        -4.06313143e-01, -7.70364482e-01, -2.84345446e+00,  3.57446433e-01,\n",
       "        -7.34262276e-01,  1.05745500e+00, -1.76236574e+00,  2.22637453e+00,\n",
       "         3.53030414e-01,  3.01672743e+00, -2.55914014e+00,  1.14131261e+00,\n",
       "         1.65645525e+00,  6.02760959e-01,  3.75715766e-01,  1.75106958e+00,\n",
       "         8.47035377e-01,  1.62082271e+00, -7.99582329e-01, -2.67805424e+00,\n",
       "         3.64195507e-01,  2.42320911e+00,  2.74296862e-01,  1.44481941e+00,\n",
       "        -2.26156350e-01,  1.42536678e+00,  2.87720974e-01,  2.66371890e+00,\n",
       "         1.10255826e+00,  8.01901953e-01, -1.36975293e+00, -1.48370043e+00,\n",
       "         2.80401032e-01, -2.13517081e+00, -8.50927540e-01, -1.12842602e+00,\n",
       "        -2.19284926e-01, -4.10408043e-01, -2.60042608e+00, -2.50758043e+00,\n",
       "        -8.57305144e-01,  9.49228699e-01, -2.83161404e+00, -1.45160791e+00,\n",
       "         7.78588509e-01,  8.52626106e-01, -6.08975172e-01,  3.21471051e-01,\n",
       "         2.68606609e+00, -5.40038399e-01,  3.05235149e+00,  1.23850828e+00,\n",
       "         8.56679487e-01,  1.46981199e+00,  7.97985578e-01,  8.62889854e-01,\n",
       "        -3.01893898e+00, -2.51963882e+00,  6.64889337e-01,  2.30649652e+00,\n",
       "        -4.36510065e-01,  8.95227089e-01,  6.59153717e-01,  1.69261082e-02,\n",
       "        -8.58002159e-01,  1.31398104e+00,  1.15643631e+00,  1.44388352e+00,\n",
       "         7.08806225e-01,  7.66778251e-01,  1.04955876e+00,  5.85450496e-01,\n",
       "        -1.20492235e-01, -2.35481927e+00,  1.54979642e+00,  4.90364176e-01,\n",
       "         1.02324975e+00,  9.91154245e-01,  1.64410424e+00, -1.43361099e+00,\n",
       "         1.21569035e+00, -5.42293521e-01, -8.03036427e-01,  9.69681605e-02,\n",
       "         1.93786500e+00,  8.75781323e-01,  9.40126728e-01, -1.82005035e+00,\n",
       "         1.44174997e+00,  4.99613571e-01, -3.17243713e-01,  1.65965035e-01,\n",
       "        -9.16549413e-01,  1.18092888e+00,  2.26631768e+00, -1.87046213e+00,\n",
       "         2.76116515e+00, -2.38561654e+00, -1.29432519e-02, -1.28885957e+00,\n",
       "        -1.64206786e+00,  8.18381711e-01,  2.75156982e+00, -9.58213317e-01,\n",
       "         2.12311513e+00, -2.81103984e+00,  5.32683748e-01, -8.71218748e-01,\n",
       "         5.63423023e-01, -1.23450706e-01, -1.59026185e+00,  6.59585966e-01,\n",
       "         5.29537045e-02,  8.93612444e-01,  3.74592620e-01, -5.58954993e-01,\n",
       "         1.23663452e+00, -2.84388487e+00,  1.35527801e+00, -4.55729781e-01,\n",
       "        -1.49617900e+00,  2.28741225e-01,  1.41190660e+00,  1.12509923e+00,\n",
       "         7.32089908e-02, -2.01026014e+00,  1.86570526e-01, -2.15966175e+00,\n",
       "        -1.32526064e+00, -5.79802731e-01,  1.19697824e-01,  1.52737841e+00,\n",
       "         9.77339282e-01,  8.52998955e-01,  2.68392988e+00, -3.78637599e-01,\n",
       "         1.69916006e+00,  1.22885574e+00,  2.03177271e+00,  1.78726158e-01,\n",
       "        -2.59866607e-01,  1.16521462e+00, -1.15943933e+00, -1.94838733e-01,\n",
       "         1.81382061e+00, -9.35433774e-01, -2.39111482e-02,  2.76931042e+00,\n",
       "         1.15448048e+00,  5.79582522e-02, -8.22651908e-01, -4.66702528e-01,\n",
       "        -2.67337875e+00,  3.68923866e-01,  1.47705192e+00,  9.76078246e-01,\n",
       "        -2.45892317e-01, -2.54883352e-02,  2.43596144e+00, -9.56464172e-01,\n",
       "        -3.20831798e-02,  4.35570844e-01, -1.63323054e+00,  9.63014513e-01,\n",
       "         1.16009553e+00,  2.04296539e+00, -1.40782266e+00,  1.46923769e-01,\n",
       "         6.00972634e-01, -2.39830780e+00, -9.90277702e-01,  3.85174661e-02,\n",
       "         8.59248475e-01,  2.19647473e+00,  3.11960137e+00,  5.16490702e-01,\n",
       "        -5.96016581e-01, -7.87147210e-01,  2.29759110e+00,  1.66339403e+00,\n",
       "         1.53380154e+00,  4.38100402e-01,  1.86236864e-01,  2.16498989e-01,\n",
       "        -4.09320479e-01, -1.27981422e+00, -2.02042978e+00, -1.41705480e+00,\n",
       "         1.86306289e+00,  1.61488170e+00,  3.48019577e+00,  2.31499473e+00,\n",
       "         2.02766240e+00,  1.08718707e-01,  1.73439600e+00,  9.43771140e-01,\n",
       "        -3.48980640e-01, -6.60592983e-01,  8.23803080e-02,  4.39497003e-01,\n",
       "        -8.23780635e-04,  8.82712819e-02, -5.54454646e-01,  1.92006361e+00,\n",
       "        -5.69690788e-01,  1.91714959e+00, -1.58461806e+00,  7.72585364e-03,\n",
       "        -1.69598384e+00,  1.46625559e+00, -2.90436514e-01, -1.28136812e+00,\n",
       "         6.52950026e-01, -6.09271864e-01, -2.06972781e+00,  7.81459067e-01,\n",
       "        -1.95351576e+00, -1.07458691e+00, -1.84579972e+00,  4.01527637e-01,\n",
       "        -1.85834649e+00, -7.16294624e-01,  4.81930069e-01, -1.06098251e+00,\n",
       "         7.09676603e-01, -7.86572388e-01, -1.27640222e+00, -4.18578497e-01,\n",
       "        -2.66495058e+00,  1.48876571e+00,  1.73175863e+00,  1.13423166e+00,\n",
       "         1.36965295e+00,  1.39573767e+00, -1.08226798e+00, -1.31416018e-01,\n",
       "         3.15611540e-01,  4.38238980e+00, -1.39911981e+00, -2.11950454e+00,\n",
       "         6.61195932e-02,  3.22311879e+00,  8.43635520e-01, -2.92782015e+00,\n",
       "        -3.42470928e+00,  1.26527193e+00,  7.63121849e-01, -7.64157464e-01,\n",
       "         2.77536919e+00, -6.55002206e-01,  1.83879983e+00, -7.79224163e-02,\n",
       "         1.17380818e+00, -3.19799086e-01,  1.03742774e+00, -1.04199944e+00,\n",
       "         2.64930110e+00,  1.25946599e+00,  8.93583416e-01, -1.12909465e+00,\n",
       "         1.55242651e+00,  1.72969525e+00, -1.96853894e+00, -3.03103333e-01,\n",
       "         3.04780519e-01, -1.55187006e+00, -1.77273782e+00,  1.35321320e+00,\n",
       "        -7.13767935e-01, -2.31283016e+00,  1.68818856e+00,  7.64464521e-01,\n",
       "        -5.94393663e-01, -2.54869901e+00,  1.55704757e+00,  1.06012837e+00,\n",
       "         2.93844505e+00, -3.81689195e-01,  2.63470918e-01, -1.61888297e+00,\n",
       "         6.35481990e-01, -4.30964841e-02, -5.44795642e-01, -6.69549121e-01,\n",
       "         2.52194515e-01,  4.64662731e-01, -1.28363823e+00,  1.47702945e-01,\n",
       "        -5.18743383e-01,  8.13192335e-01,  1.73580760e+00,  8.74474492e-01,\n",
       "         2.38098283e-01,  6.72507374e-01, -8.54657354e-01,  1.01647598e+00,\n",
       "        -2.45891675e-01, -4.02643553e-02, -1.27918826e+00,  2.28848806e+00,\n",
       "         4.53130435e-01, -2.73794393e-01,  3.01034804e-01, -6.86244126e-01,\n",
       "         1.17522032e-01, -1.69932630e+00, -1.14934309e+00, -2.70521930e-01,\n",
       "         6.74804512e-01, -3.33152611e+00, -2.04945682e-01, -1.12799162e+00,\n",
       "        -2.43668138e+00,  3.81643811e+00, -1.68978136e+00,  8.78573109e-01,\n",
       "         2.02929872e+00, -2.46232557e-02, -8.83229021e-01,  2.48199487e-02,\n",
       "        -9.22340109e-02,  2.60926636e+00,  3.02388044e+00, -4.02571173e-01,\n",
       "         9.20951026e-01,  4.79462230e-01,  1.11531964e+00,  2.31003400e+00,\n",
       "        -1.97019125e+00,  1.10938240e+00, -6.69863492e-01,  5.82506007e-01,\n",
       "         1.35024316e+00,  8.97766599e-01,  2.38948307e+00,  8.99913304e-01,\n",
       "         2.91049516e-01, -3.93149474e+00,  1.82370303e+00,  2.75842443e+00,\n",
       "         2.46298962e+00,  2.12655426e-01, -3.13298225e+00,  5.21850365e-02,\n",
       "         1.06999603e+00,  3.52607204e-01, -1.34272470e+00,  2.94550043e-02,\n",
       "         4.49535281e-01,  1.63802182e-01, -4.86905764e-01,  4.78299437e-02,\n",
       "         7.58374940e-01,  3.04966871e+00,  1.20326101e-02, -1.97133434e+00,\n",
       "         6.70986926e-01,  2.95608916e-01,  1.69946028e+00, -1.41762360e+00,\n",
       "        -5.90348782e-01,  1.60273704e-02,  9.35956929e-02,  2.39609053e+00,\n",
       "        -2.32817057e-01, -2.50340428e-01,  6.71182407e-01,  1.32787831e-01,\n",
       "         2.07431023e-01, -5.47821069e-01, -1.86168094e+00,  1.57385279e+00,\n",
       "         3.82657177e-01,  1.42532818e+00, -6.01544299e-01,  5.63644496e-01,\n",
       "        -1.84477735e+00, -1.11079414e+00, -1.52615015e+00,  6.29504712e-01,\n",
       "         3.13058565e+00,  5.35424575e-01,  1.00665378e+00, -4.31437300e-01,\n",
       "         9.44542440e-01, -6.96732217e-01, -3.79195285e-01,  9.47743991e-01,\n",
       "         4.79123866e-01, -8.92936644e-01,  1.64078112e+00, -8.84528713e-01,\n",
       "         9.05979318e-01,  8.48962149e-01, -4.09805359e-01,  2.73830139e+00,\n",
       "         3.30039098e+00,  1.69085534e+00, -1.96820858e+00, -5.67316230e-01,\n",
       "        -1.26573246e+00, -2.54415858e+00, -3.18724270e-01,  2.16099479e+00,\n",
       "        -1.71038853e+00, -3.99012528e-02,  3.01112116e+00, -6.43682914e-01,\n",
       "         2.49494817e+00,  6.11113403e-01, -1.72843647e+00, -3.00981278e-01,\n",
       "         2.28374345e+00, -9.18084937e-01,  9.71356049e-01,  1.93509518e+00,\n",
       "        -6.64393683e-01,  1.11852241e+00, -1.38364651e+00,  2.00763665e-01,\n",
       "         1.24994217e+00,  8.53729042e-01,  2.74274530e+00, -5.52188766e-01,\n",
       "         6.43767929e-01,  6.56239016e-01,  4.50758569e-01,  2.13781855e+00,\n",
       "        -8.78312409e-01, -2.51796945e+00, -1.35664614e+00,  4.16133520e-01,\n",
       "         4.67412320e-01, -1.52374418e+00, -1.05792479e-01, -1.59041838e+00,\n",
       "         3.26192210e+00,  6.67116419e-01,  2.37028182e+00, -2.04180758e+00,\n",
       "         3.69445234e-02,  1.61890786e+00, -2.54301897e+00, -4.23810449e-01,\n",
       "        -3.72301398e-01, -2.82987828e+00,  8.04438535e-01, -3.08509351e+00,\n",
       "        -2.70277270e-01,  1.19886616e+00,  5.51999358e-01, -2.21257755e+00]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_orth_score(y, d, l_hat, m_hat, g_hat, smpls):\n",
    "    u_hat = y - g_hat\n",
    "    psi_a = -np.multiply(d, d)\n",
    "    psi_b = np.multiply(d, u_hat)\n",
    "    return psi_a, psi_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark that the estimator is not able to estimate $\\hat{g}_0(X)$ directly, but has to be based on a preliminary estimate of $\\hat{m}_0(X)$. All following estimators with ``score=\"IV-type\"`` are based on the same preliminary procedure. Furthermore, remark that we are using external predictions to avoid cross-fitting (for demonstration purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication 59/1000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m i_train, i_est \u001b[38;5;241m=\u001b[39m train_test_split(np\u001b[38;5;241m.\u001b[39marange(n_obs), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# fit the ML algorithms on the training sample\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m ml_l\u001b[38;5;241m.\u001b[39mfit(x[i_train, :], y[i_train])\n\u001b[1;32m     20\u001b[0m ml_m\u001b[38;5;241m.\u001b[39mfit(x[i_train, :], d[i_train])\n\u001b[1;32m     22\u001b[0m psi_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mmultiply(d[i_train] \u001b[38;5;241m-\u001b[39m ml_m\u001b[38;5;241m.\u001b[39mpredict(x[i_train, :]), d[i_train] \u001b[38;5;241m-\u001b[39m ml_m\u001b[38;5;241m.\u001b[39mpredict(x[i_train, :]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1398\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   1399\u001b[0m         X,\n\u001b[1;32m   1400\u001b[0m         y,\n\u001b[1;32m   1401\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1402\u001b[0m         init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[1;32m   1403\u001b[0m         eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[1;32m   1404\u001b[0m         eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1405\u001b[0m         eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[1;32m   1406\u001b[0m         eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[1;32m   1407\u001b[0m         eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[1;32m   1408\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[1;32m   1409\u001b[0m         categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[1;32m   1410\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1411\u001b[0m         init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1412\u001b[0m     )\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m   1050\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m   1051\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m   1052\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[1;32m   1053\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1054\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1055\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m   1057\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1058\u001b[0m )\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    311\u001b[0m     cb(\n\u001b[1;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[1;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4154\u001b[0m _safe_call(\n\u001b[0;32m-> 4155\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   4156\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   4157\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[1;32m   4158\u001b[0m     )\n\u001b[1;32m   4159\u001b[0m )\n\u001b[1;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(1111)\n",
    "\n",
    "ml_l = LGBMRegressor(n_estimators=300, learning_rate=0.1, verbose=-1)\n",
    "ml_m = LGBMRegressor(n_estimators=300, learning_rate=0.1, verbose=-1)\n",
    "\n",
    "ml_g = clone(ml_l)\n",
    "\n",
    "theta_nonorth = np.full(n_rep, np.nan)\n",
    "se_nonorth = np.full(n_rep, np.nan) \n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    print(f'Replication {i_rep+1}/{n_rep}', end='\\r')\n",
    "    (x, y, d) = data[i_rep]\n",
    "    \n",
    "    # choose a random sample for training and estimation\n",
    "    i_train, i_est = train_test_split(np.arange(n_obs), test_size=0.5, random_state=42)\n",
    "    \n",
    "    # fit the ML algorithms on the training sample\n",
    "    ml_l.fit(x[i_train, :], y[i_train])\n",
    "    ml_m.fit(x[i_train, :], d[i_train])\n",
    "\n",
    "    psi_a = -np.multiply(d[i_train] - ml_m.predict(x[i_train, :]), d[i_train] - ml_m.predict(x[i_train, :]))\n",
    "    psi_b = np.multiply(d[i_train] - ml_m.predict(x[i_train, :]), y[i_train] - ml_l.predict(x[i_train, :]))\n",
    "    theta_initial = -np.nanmean(psi_b) / np.nanmean(psi_a)\n",
    "    ml_g.fit(x[i_train, :], y[i_train] - theta_initial * d[i_train])\n",
    "\n",
    "    # create out-of-sample predictions\n",
    "    l_hat = ml_l.predict(x[i_est, :])\n",
    "    m_hat = ml_m.predict(x[i_est, :])\n",
    "    g_hat = ml_g.predict(x[i_est, :])\n",
    "\n",
    "    external_predictions = {\n",
    "        'd': {\n",
    "            'ml_l': l_hat.reshape(-1, 1),\n",
    "            'ml_m': m_hat.reshape(-1, 1),\n",
    "            'ml_g': g_hat.reshape(-1, 1)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x[i_est, :], y[i_est], d[i_est])\n",
    "    obj_dml_plr_nonorth = DoubleMLPLR(obj_dml_data,\n",
    "                                    ml_l, ml_m, ml_g,\n",
    "                                    n_folds=2,\n",
    "                                    score=non_orth_score)\n",
    "    obj_dml_plr_nonorth.fit(external_predictions=external_predictions)\n",
    "    theta_nonorth[i_rep] = obj_dml_plr_nonorth.coef[0]\n",
    "    se_nonorth[i_rep] = obj_dml_plr_nonorth.se[0]\n",
    "\n",
    "fig_non_orth, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_nonorth - alpha)/se_nonorth,\n",
    "                color=face_colors[0], edgecolor = edge_colors[0],\n",
    "                stat='density', bins=30, label='Non-orthogonal ML');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));\n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization bias in the simple ML-approach is caused by the slow convergence of $\\hat{\\theta}_0$\n",
    "\n",
    "$$\n",
    "|\\sqrt{n} (\\hat{\\theta}_0 - \\theta_0) | \\rightarrow_{P} \\infty\n",
    "$$\n",
    "\n",
    "i.e., slower than $1/\\sqrt{n}$.\n",
    "The driving factor is the bias that arises by learning $g$ with a random forest or any other ML technique.\n",
    "A heuristic illustration is given by\n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\theta}_0 - \\theta_0) = \\underbrace{\\left(\\frac{1}{n} \\sum_{i\\in I} D_i^2\\right)^{-1} \\frac{1}{n} \\sum_{i\\in I} D_i \\zeta_i}_{=:a}\n",
    "+  \\underbrace{\\left(\\frac{1}{n} \\sum_{i\\in I} D_i^2\\right)^{-1} \\frac{1}{n} \\sum_{i\\in I} D_i (g_0(X_i) - \\hat{g}_0(X_i))}_{=:b}.\n",
    "$$\n",
    "\n",
    "$a$ is approximately Gaussian under mild conditions.\n",
    "However, $b$ (the regularization bias) diverges in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overcoming regularization bias by orthogonalization\n",
    "\n",
    "To overcome the regularization bias we can partial out the effect of $X$ from $D$ to obtain the orthogonalized regressor $V = D - m(X)$. We then use the final estimate\n",
    "\n",
    "$$\n",
    "\\check{\\theta}_0 = \\left(\\frac{1}{n} \\sum_{i\\in I} \\hat{V}_i D_i\\right)^{-1} \\frac{1}{n} \\sum_{i\\in I} \\hat{V}_i (Y_i - \\hat{g}_0(X_i)).\n",
    "$$\n",
    "\n",
    "The following figure shows the distribution of the resulting estimates $\\hat{\\theta}_0$ without sample-splitting. Again, we are using external predictions to avoid cross-fitting (for demonstration purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2222)\n",
    "\n",
    "theta_orth_nosplit = np.full(n_rep, np.nan)\n",
    "se_orth_nosplit = np.full(n_rep, np.nan)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    print(f'Replication {i_rep+1}/{n_rep}', end='\\r')\n",
    "    (x, y, d) = data[i_rep]\n",
    "\n",
    "    # fit the ML algorithms on the training sample\n",
    "    ml_l.fit(x, y)\n",
    "    ml_m.fit(x, d)\n",
    "\n",
    "    psi_a = -np.multiply(d - ml_m.predict(x), d - ml_m.predict(x))\n",
    "    psi_b = np.multiply(d - ml_m.predict(x), y - ml_l.predict(x))\n",
    "    theta_initial = -np.nanmean(psi_b) / np.nanmean(psi_a)\n",
    "    ml_g.fit(x, y - theta_initial * d)\n",
    "\n",
    "    l_hat = ml_l.predict(x)\n",
    "    m_hat = ml_m.predict(x)\n",
    "    g_hat = ml_g.predict(x)\n",
    "\n",
    "    external_predictions = {\n",
    "        'd': {\n",
    "            'ml_l': l_hat.reshape(-1, 1),\n",
    "            'ml_m': m_hat.reshape(-1, 1),\n",
    "            'ml_g': g_hat.reshape(-1, 1)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    \n",
    "    obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                        ml_l, ml_m, ml_g,\n",
    "                                        score='IV-type')\n",
    "    obj_dml_plr_orth_nosplit.fit(external_predictions=external_predictions)\n",
    "    theta_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "    se_orth_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]\n",
    "\n",
    "fig_orth_nosplit, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_orth_nosplit - alpha)/se_orth_nosplit,\n",
    "                color=face_colors[1], edgecolor = edge_colors[1],\n",
    "                stat='density', bins=30, label='Double ML (no sample splitting)');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));    \n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the nuisance models $\\hat{g}_0()$ and $\\hat{m}()$ are estimated on the whole dataset, which is also used for obtaining the final estimate $\\check{\\theta}_0$, another bias is observed.\n",
    "\n",
    "## Sample splitting to remove bias induced by overfitting\n",
    "\n",
    "Using sample splitting, i.e., estimate the nuisance models $\\hat{g}_0()$ and $\\hat{m}()$ on one part of the data (training data) and estimate $\\check{\\theta}_0$ on the other part of the data (test data), overcomes the bias induced by overfitting. We can exploit the benefits of cross-fitting by switching the role of the training and test sample. Cross-fitting performs well empirically because the entire sample can be used for estimation.\n",
    "\n",
    "The following figure shows the distribution of the resulting estimates $\\hat{\\theta}_0$ with orthogonal score and sample-splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3333)\n",
    "\n",
    "theta_dml = np.full(n_rep, np.nan)\n",
    "se_dml = np.full(n_rep, np.nan)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "    print(f'Replication {i_rep+1}/{n_rep}', end='\\r')\n",
    "    (x, y, d) = data[i_rep]\n",
    "    obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "    obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                            ml_l, ml_m, ml_g,\n",
    "                            n_folds=2,\n",
    "                            score='IV-type')\n",
    "    obj_dml_plr.fit()\n",
    "    theta_dml[i_rep] = obj_dml_plr.coef[0]\n",
    "    se_dml[i_rep] = obj_dml_plr.se[0]\n",
    "\n",
    "fig_dml, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_dml - alpha)/se_dml,\n",
    "                color=face_colors[2], edgecolor = edge_colors[2],\n",
    "                stat='density', bins=30, label='Double ML with cross-fitting');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));\n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double/debiased machine learning\n",
    "\n",
    "To illustrate the benefits of the auxiliary prediction step in the DML framework we write the error as\n",
    "\n",
    "$$\n",
    "\\sqrt{n}(\\check{\\theta}_0 - \\theta_0) = a^* + b^* + c^*\n",
    "$$\n",
    "\n",
    "Chernozhukov et al. (2018) argues that:\n",
    "\n",
    "The first term\n",
    "\n",
    "$$\n",
    "a^* := (EV^2)^{-1} \\frac{1}{\\sqrt{n}} \\sum_{i\\in I} V_i \\zeta_i\n",
    "$$\n",
    "\n",
    "will be asymptotically normally distributed.\n",
    "\n",
    "The second term\n",
    "\n",
    "$$\n",
    "b^* := (EV^2)^{-1} \\frac{1}{\\sqrt{n}} \\sum_{i\\in I} (\\hat{m}(X_i) - m(X_i)) (\\hat{g}_0(X_i) - g_0(X_i))\n",
    "$$\n",
    "\n",
    "vanishes asymptotically for many data generating processes.\n",
    "\n",
    "The third term $c^*$ vanishes in probability if sample splitting is applied. Finally, let us compare all distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "fig_all, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_nonorth - alpha)/se_nonorth,\n",
    "                 color=face_colors[0], edgecolor = edge_colors[0],\n",
    "                 stat='density', bins=30, label='Non-orthogonal ML');\n",
    "sns.histplot((theta_orth_nosplit - alpha)/se_orth_nosplit,\n",
    "             color=face_colors[1], edgecolor = edge_colors[1],\n",
    "             stat='density', bins=30, label='Double ML (no sample splitting)');\n",
    "sns.histplot((theta_dml - alpha)/se_dml,\n",
    "             color=face_colors[2], edgecolor = edge_colors[2],\n",
    "             stat='density', bins=30, label='Double ML with cross-fitting');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));\n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partialling out score\n",
    "\n",
    "Another debiased estimator, based on the partialling-out approach of Robinson(1988), is\n",
    "\n",
    "$$\n",
    "\\check{\\theta}_0 = \\left(\\frac{1}{n} \\sum_{i\\in I} \\hat{V}_i \\hat{V}_i \\right)^{-1} \\frac{1}{n} \\sum_{i\\in I} \\hat{V}_i (Y_i - \\hat{\\ell}_0(X_i)),\n",
    "$$\n",
    "\n",
    "with $\\ell_0(X_i) = E(Y|X)$.\n",
    "All nuisance parameters for the estimator with `score='partialling out'` are conditional mean functions, which can be directly estimated using ML methods. This is a minor advantage over the estimator with `score='IV-type'`.\n",
    "In the following, we repeat the above analysis with `score='partialling out'`. In a first part of the analysis, we estimate $\\theta_0$ without sample splitting. Again we observe a bias from overfitting.\n",
    "\n",
    "The following figure shows the distribution of the resulting estimates $\\hat{\\theta}_0$ without sample-splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4444)\n",
    "\n",
    "theta_orth_po_nosplit = np.full(n_rep, np.nan)\n",
    "se_orth_po_nosplit = np.full(n_rep, np.nan)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "     print(f'Replication {i_rep+1}/{n_rep}', end='\\r')\n",
    "     (x, y, d) = data[i_rep]\n",
    "\n",
    "     # fit the ML algorithms on the training sample\n",
    "     ml_l.fit(x, y)\n",
    "     ml_m.fit(x, d)\n",
    "\n",
    "     l_hat = ml_l.predict(x)\n",
    "     m_hat = ml_m.predict(x)\n",
    "\n",
    "     external_predictions = {\n",
    "          'd': {\n",
    "               'ml_l': l_hat.reshape(-1, 1),\n",
    "               'ml_m': m_hat.reshape(-1, 1),\n",
    "          }\n",
    "     }\n",
    "\n",
    "     obj_dml_plr_orth_nosplit = DoubleMLPLR(obj_dml_data,\n",
    "                                         ml_l, ml_m,\n",
    "                                         score='partialling out')\n",
    "     obj_dml_plr_orth_nosplit.fit(external_predictions=external_predictions)\n",
    "     theta_orth_po_nosplit[i_rep] = obj_dml_plr_orth_nosplit.coef[0]\n",
    "     se_orth_po_nosplit[i_rep] = obj_dml_plr_orth_nosplit.se[0]\n",
    "\n",
    "fig_po_nosplit, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_orth_po_nosplit - alpha)/se_orth_po_nosplit,\n",
    "                 color=face_colors[1], edgecolor = edge_colors[1],\n",
    "                 stat='density', bins=30, label='Double ML (no sample splitting)');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));\n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sample splitting, overcomes the bias induced by overfitting.\n",
    "Again, the implementation automatically applies cross-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5555)\n",
    "\n",
    "theta_dml_po = np.full(n_rep, np.nan)\n",
    "se_dml_po = np.full(n_rep, np.nan)\n",
    "\n",
    "for i_rep in range(n_rep):\n",
    "     print(f'Replication {i_rep+1}/{n_rep}', end='\\r')\n",
    "     (x, y, d) = data[i_rep]\n",
    "     obj_dml_data = DoubleMLData.from_arrays(x, y, d)\n",
    "     obj_dml_plr = DoubleMLPLR(obj_dml_data,\n",
    "                             ml_l, ml_m,\n",
    "                             n_folds=2,\n",
    "                             score='partialling out')\n",
    "     obj_dml_plr.fit()\n",
    "     theta_dml_po[i_rep] = obj_dml_plr.coef[0]\n",
    "     se_dml_po[i_rep] = obj_dml_plr.se[0]\n",
    " \n",
    "fig_po_dml, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_dml_po - alpha)/se_dml_po,\n",
    "                 color=face_colors[2], edgecolor = edge_colors[2],\n",
    "                 stat='density', bins=30, label='Double ML with cross-fitting');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));\n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us compare all distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_po_all, ax = plt.subplots(constrained_layout=True);\n",
    "ax = sns.histplot((theta_nonorth - alpha)/se_nonorth,\n",
    "                color=face_colors[0], edgecolor = edge_colors[0],\n",
    "                stat='density', bins=30, label='Non-orthogonal ML');\n",
    "sns.histplot((theta_orth_po_nosplit - alpha)/se_orth_po_nosplit,\n",
    "            color=face_colors[1], edgecolor = edge_colors[1],\n",
    "            stat='density', bins=30, label='Double ML (no sample splitting)');\n",
    "sns.histplot((theta_dml_po - alpha)/se_dml_po,\n",
    "            color=face_colors[2], edgecolor = edge_colors[2],\n",
    "            stat='density', bins=30, label='Double ML with cross-fitting');\n",
    "ax.axvline(0., color='k');\n",
    "xx = np.arange(-5, +5, 0.001)\n",
    "yy = stats.norm.pdf(xx)\n",
    "ax.plot(xx, yy, color='k', label='$\\\\mathcal{N}(0, 1)$');\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0));\n",
    "ax.set_xlim([-6., 6.]);\n",
    "ax.set_xlabel('$(\\hat{\\\\theta}_0 - \\\\theta_0)/\\hat{\\sigma}$');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all figures\n",
    "fig_non_orth.savefig('../guide/figures/py_non_orthogonal.svg', dpi=300, bbox_inches='tight', format='svg')\n",
    "fig_orth_nosplit.savefig('../guide/figures/py_dml_nosplit.svg', dpi=300, bbox_inches='tight', format='svg')\n",
    "fig_dml.savefig('../guide/figures/py_dml.svg', dpi=300, bbox_inches='tight', format='svg')\n",
    "fig_all.savefig('../guide/figures/py_all.svg', dpi=300, bbox_inches='tight', format='svg')\n",
    "\n",
    "fig_po_nosplit.savefig('../guide/figures/py_dml_po_nosplit.svg', dpi=300, bbox_inches='tight', format='svg')\n",
    "fig_po_dml.savefig('../guide/figures/py_dml_po.svg', dpi=300, bbox_inches='tight', format='svg')\n",
    "fig_po_all.savefig('../guide/figures/py_po_all.svg', dpi=300, bbox_inches='tight', format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
